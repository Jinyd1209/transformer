{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79a0955",
   "metadata": {},
   "source": [
    "# <big>Transformer</big>\n",
    "\n",
    "**Author: yidong jin**\n",
    "\n",
    "**Date: 2023-5-21**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79cfa5",
   "metadata": {},
   "source": [
    "![pic1](png/pic1.png)\n",
    "## å®è§‚ä¸Šçœ‹transformerç»“æ„ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š\n",
    "1. Embedding\n",
    "    * token embedding\n",
    "    * position encoding\n",
    "2. Encoder\n",
    "    * mutil-head attention\n",
    "    * layer normalization and residual connect\n",
    "    * feed forward layer\n",
    "3. Decoder\n",
    "    * masked mutil-head attention\n",
    "    * layer normalization and residual connect\n",
    "    * mutil-head attention\n",
    "    * feed forward layer\n",
    "4. output layer\n",
    "    * linear layer\n",
    "    * softmax\n",
    "\n",
    "    \n",
    "**æ•´ä¸ªç½‘ç»œçš„åŸºæœ¬æµç¨‹ä¸ºè¾“å…¥å…ˆç»è¿‡embeddingè¢«ç¼–ç æˆå‘é‡ï¼Œå› ä¸ºå‘é‡ä¸å¸¦æœ‰ä½ç½®ä¿¡æ¯ï¼Œå› æ­¤éœ€è¦æ ¹æ®è¾“å…¥æ¯å¥è¯ä¸­è¯çš„ä½ç½®æ¥ç¼–ç ä¸€ä¸ªä½ç½®å‘é‡ï¼Œå°†è¿™ä¸¤ä¸ªå‘é‡ç›¸åŠ åè¾“å…¥ç¼–ç å™¨ï¼Œç¼–ç å™¨ä¸»è¦åŒ…å«ä¸‰éƒ¨åˆ†ï¼Œç¬¬ä¸€éƒ¨åˆ†å°±æ˜¯æœ€æ ¸å¿ƒçš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œè¾“å…¥é€šè¿‡æ­¤æ¨¡å—å¾—åˆ°ä¸åŒå‘é‡ä¹‹é—´çš„æ³¨æ„åŠ›ç³»æ•°ï¼Œæ¥ç€å°±æ˜¯ä¸€ä¸ªå±‚å½’ä¸€åŒ–å’Œæ®‹å·®è¿æ¥ï¼Œæœ€åçš„feed forward layerå…¶æœ¬è´¨å°±æ˜¯ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œè§£ç å™¨å’Œç¼–ç å™¨çš„ä¸åŒä¹‹å¤„ä¸»è¦æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯maskè¿‡çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œå¦ä¸€ä¸ªæ˜¯ç¬¬äºŒä¸ªå¤šå¤´æ³¨æ„åŠ›æ¨¡å—çš„è¾“å…¥æœ‰ä¸€éƒ¨åˆ†ç›´æ¥æ¥è‡ªäºç¼–ç å™¨ï¼ŒåŒæ—¶è§£ç å™¨éœ€è¦è¾“å…¥æ¯ä¸€ä¸ªè¾“å…¥çš„çœŸå®æ ‡ç­¾æ¥è¾…åŠ©è®­ç»ƒï¼Œè¿™ç§æŠ€æœ¯å«åšteacher-forcingï¼Œè¿™ä¼šæ˜¾è‘—çš„æ”¹å–„æ¨¡å‹è®­ç»ƒéš¾åº¦å¹¶åŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œæœ€åå†ç»è¿‡ä¸€ä¸ªçº¿æ€§å±‚å’Œsoftmaxå‡½æ•°å°±å¾—åˆ°äº†æœ€ç»ˆçš„æ¦‚ç‡çŸ©é˜µã€‚æ¥ä¸‹æ¥å¼€å§‹æŒ‰é¡ºåºä¸€æ­¥æ­¥æ­å»ºå‡ºtransformeræ¨¡å‹ï¼Œlet's start,coding is all you need!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a487dc",
   "metadata": {},
   "source": [
    "## embedding\n",
    "**é¦–å…ˆæˆ‘ä»¬å¼€å§‹å®šä¹‰token embeddingå’Œposition encodingï¼Œtoken embeddingæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨`torh.nn.Embedding`ï¼Œposition encodingåˆ™æ ¹æ®åŸè®ºæ–‡ä¸­çš„å…¬å¼è¿›è¡Œç¼–å†™ã€‚**\n",
    "\n",
    "![pic3](png/pic3.png)\n",
    "\n",
    "**åœ¨åšembeddingä¹‹å‰é¦–å…ˆè¦æ˜ç¡®æˆ‘ä»¬ä¼ å…¥çš„æ•°æ®å½¢å¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯ç›´æ¥æŠŠä¸€å¥è¯çš„æ¯ä¸ªè¯éƒ½ç›´æ¥ä¼ å…¥ç½‘ç»œï¼Œè€Œæ˜¯ä¼šæœ‰ä¸€ä¸ªvocabularyå­—å…¸ï¼Œæ¯ä¸€ä¸ªå•è¯éƒ½å¯¹åº”ä¸€ä¸ªå”¯ä¸€çš„ç´¢å¼•ï¼Œåœ¨ä¼ å…¥ç½‘ç»œå‰æˆ‘ä»¬ä¼šå°†æ¯ä¸ªå•è¯éƒ½mappingåˆ°å…¶ç´¢å¼•ä¸Šã€‚ä¸¾ä¸ªä¾‹å­ï¼Œç°åœ¨æœ‰ä¸€å¥è¯â€œhello world!\"ï¼Œé¦–å…ˆå°†å…¶åˆ†ç¦»æˆå•ä¸ªå­—ç¬¦å­˜å‚¨åœ¨åˆ—è¡¨é‡Œå¾—åˆ°[['hello','world','!']]ï¼Œè¿™é‡Œä½¿ç”¨åµŒå¥—åˆ—è¡¨æ˜¯å› ä¸ºé€šå¸¸æˆ‘ä»¬ä¸€æ¬¡è¾“å…¥ç½‘ç»œä¸æ­¢ä¸€ä¸ªå¥å­ï¼Œå¤–å±‚åˆ—è¡¨çš„é•¿åº¦å³æ˜¯batch size,æ¥ç€å°†æ¯ä¸€ä¸ªè¯æ˜ å°„åˆ°vocabularyä¸­ï¼Œå¾—åˆ°ä¸€ä¸ªç´¢å¼•åˆ—è¡¨[[3,5,2]]ï¼Œè¿™ä¸ªç´¢å¼•åˆ—è¡¨å³æ˜¯æˆ‘ä»¬éœ€è¦ä¼ å…¥ç½‘ç»œçš„è¾“å…¥ã€‚ä¼ å…¥torchçš„embeddingå‡½æ•°åå‡½æ•°ä¼šæ ¹æ®ä½ çš„å•è¯æ•°é‡å’Œæ¯ä¸€ä¸ªè¯éœ€è¦æ˜ å°„çš„ç»´åº¦æŠŠæ¯ä¸€å¥è¯éƒ½å¤„ç†æˆä¸€ä¸ªç»´åº¦ä¸º[seq_len,embedding_dim]çš„äºŒç»´çŸ©é˜µï¼Œè¿™ä¸ªäºŒç»´çŸ©é˜µçš„æ¯ä¸€è¡Œå³ä¸ºä¸€ä¸ªè¯å‘é‡ï¼Œè¯å‘é‡çš„ç»´åº¦å–å†³äºä½ çš„vocabularyæœ‰å¤šå¤§ï¼Œä½ çš„å­—å…¸é‡Œçš„è¯è¶Šå¤šå°±éœ€è¦è¶Šå¤§çš„ç»´åº¦å»è¦†ç›–æ‰€æœ‰çš„è¯ã€‚æ¥ç€æˆ‘ä»¬æ¥çœ‹postion encodingçš„å…¬å¼ï¼Œå…¶ä¸­posä»£è¡¨æ¯ä¸ªè¯åœ¨å¥å­ä¸­çš„ä½ç½®ï¼Œiä»£è¡¨è¯å‘é‡ç»´åº¦çš„ç´¢å¼•ï¼Œç®€å•æ˜äº†ï¼Œåªéœ€è¦æŒ‰ç…§å…¬å¼å®ç°å³å¯ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7e0fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Token_Embedding(nn.Embedding):\n",
    "    def __init__(self,voc_num,d_model):\n",
    "        super().__init__(voc_num,d_model,padding_idx=0)\n",
    "\n",
    "        \n",
    "class Position_Encoder(nn.Module):\n",
    "    def __init__(self,d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self,x):\n",
    "        batch,seq_len = x.size()\n",
    "        # ä½ç½®ç¼–ç ä¸éœ€è¦å‚ä¸æ¢¯åº¦æ›´æ–°\n",
    "        pos_encoding = torch.zeros((seq_len,self.d_model),requires_grad=False)\n",
    "        idx = torch.arange(0,seq_len).unsqueeze(dim=1)\n",
    "        col_2_interval = torch.arange(0,self.d_model,2)\n",
    "        # éå†çŸ©é˜µæ¯ä¸€ä¸ªå€¼ä¹Ÿå¯ä»¥ä½†å¤ªlowï¼Œå®Œå…¨æ²¡æœ‰åˆ©ç”¨çŸ©é˜µè¿ç®—çš„å¹¶è¡Œç‰¹æ€§ï¼Œä¸è€ƒè™‘ä½¿ç”¨\n",
    "        # TODO:æ˜¯å¦å¯ä»¥ç»Ÿä¸€å¥‡å¶ç»´åº¦ï¼Ÿ\n",
    "        if self.d_model % 2 == 0:\n",
    "            pos_encoding[:,0::2] = torch.sin(idx / 10000 ** (col_2_interval/self.d_model)).float()\n",
    "            pos_encoding[:,1::2] = torch.cos(idx / 10000 ** (col_2_interval/self.d_model)).float()\n",
    "        else:\n",
    "            pos_encoding[:,0::2] = torch.sin(idx / 10000 ** (col_2_interval/self.d_model)).float()\n",
    "            pos_encoding[:,1::2] = torch.cos(idx / 10000 ** (col_2_interval/self.d_model))[:,:-1].float()\n",
    "        return pos_encoding\n",
    "\n",
    "    \n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self,voc_num,d_model,p_drop):\n",
    "        super().__init__()\n",
    "        self.token_emb = Token_Embedding(voc_num,d_model)\n",
    "        self.pos_emb = Position_Encoder(d_model)\n",
    "        self.drop = nn.Dropout(p=p_drop)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        token_emb = self.token_emb(x)\n",
    "        pos_emb = self.pos_emb(x)\n",
    "        return self.drop(token_emb+pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cd1d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "#embeddingæ¨¡å—æµ‹è¯•\n",
    "inp = torch.LongTensor([[1,2,4,5],[2,3,1,8]])\n",
    "emb = Embedding(10,4,0.1)\n",
    "emb_out = emb(inp)\n",
    "print(emb_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb57ee0",
   "metadata": {},
   "source": [
    "è§£é‡Šä¸‹è¿™ä¸ªçŸ©é˜µæ¯ä¸€ä¸ªç»´åº¦ä»£è¡¨ä»€ä¹ˆï¼Œç¬¬ä¸€ç»´ä»£è¡¨batch sizeå³æ¯æ¬¡æˆ‘ä»¬ä¼ å…¥çš„å¥å­æ•°é‡ï¼Œç¬¬äºŒç»´ä»£è¡¨æ¯ä¸ªå¥å­çš„å•è¯æ•°ï¼Œç¬¬ä¸‰ç»´ä»£è¡¨ç¼–ç æˆè¯å‘é‡çš„ç»´åº¦ï¼Œæˆ‘ä»¬è¾“å…¥äº†ä¸¤ä¸ªå¥å­ï¼Œæ¯ä¸ªå¥å­å››ä¸ªè¯ï¼Œå®šä¹‰ä½¿ç”¨ä¸‰ç»´çš„è¯å‘é‡è¿›è¡Œç¼–ç ï¼Œè¾“å‡ºæ­£ç¡®æµ‹è¯•é€šè¿‡ï½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd81fb7",
   "metadata": {},
   "source": [
    "# mutil-head attention\n",
    "**ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›ï¼Ÿæˆ‘ä»¬éƒ½çŸ¥é“åœ¨å¾ˆå¤šçš„è¯­è¨€ä½“ç³»ä¸­éƒ½æœ‰å¤šä¹‰è¯çš„æ¦‚å¿µï¼Œå³ä¸€ä¸ªè¯ä¼šæœ‰å¤šç§ä¸åŒçš„å«ä¹‰ï¼Œå› æ­¤äººç±»åœ¨ç¿»è¯‘ä¸€æ®µè¯ä¸­çš„æ¯ä¸€ä¸ªè¯æ—¶ä¸ä¼šåªå•ç‹¬å…³æ³¨å½“å‰è¯çš„æ„æ€ï¼Œè¿˜éœ€è¦ç»“åˆä¸Šä¸‹æ–‡æ¥æ˜ç¡®è¯¥è¯çš„ç¡®åˆ‡æ„æ€ï¼Œå› æ­¤æˆ‘ä»¬çš„æ³¨æ„åŠ›éœ€è¦è¿›è¡Œåˆ†é…ï¼Œä¸ä»…èšç„¦åœ¨å½“å‰è¯ä¸Šè¿˜éœ€è¦èšç„¦åœ¨èƒ½å¤Ÿæœ€å¤§åŒ–å¸®åŠ©æˆ‘ä»¬æ˜ç¡®å½“å‰è¯æ„æ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸Šï¼Œå½“ç„¶äººç±»å¯ä»¥è‡ªä¸»åšåˆ°è¿™äº›ï¼Œä½†æ¨¡å‹ä¸æ˜¯äººç±»ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è®¾è®¡ä¸€ç§ç®—æ³•æ¥è®©æ¨¡å‹å­¦ä¼šå¦‚ä½•å»è‡ªåŠ¨çš„åˆ†é…æ³¨æ„åŠ›è®©å…¶èƒ½æœ€å‡†ç¡®çš„ç¿»è¯‘æ¯ä¸€ä¸ªè¯ï¼Œself-attentionå°±æ­¤æå‡ºï¼Œè¯¥ç®—æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯æ¯ç¿»è¯‘ä¸€ä¸ªè¯æ—¶éƒ½ä¼šè®¡ç®—è¯¥è¯å’Œè¿™å¥è¯ä¸­å…¶ä»–çš„æ‰€æœ‰è¯çš„ç›¸å…³æ€§ï¼Œå°†ç›¸å…³æ€§é‡åŒ–åˆ°0-1ä¹‹é—´çš„æƒé‡åå’Œæ¯ä¸€ä¸ªè¯å‘é‡åšelement-wise productåå°±å¯ä»¥ä½¿ç½‘ç»œåœ¨å­¦ä¹ æ—¶å…³æ³¨æƒé‡é«˜çš„è¯å‘é‡ã€‚**\n",
    "\n",
    "**é‚£ä¹ˆé¦–å…ˆçš„é—®é¢˜å°±æ˜¯è¦ææ¸…ç›¸å…³æ€§æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Œæˆ‘ä»¬çš„è¾“å…¥åœ¨ç»è¿‡embeddingåå·²ç»å˜æˆäº†ä¸€ä¸ªä¸‰ç»´çš„çŸ©é˜µï¼ŒæŠ›å¼€batch sizeä¸çœ‹ï¼Œæˆ‘ä»¬å•ç‹¬å–å…¶ä¸­çš„ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œå…¶æœ¬è´¨å°±æ˜¯ä¸€å¥è¯çš„ç¼–ç çŸ©é˜µï¼Œæ¯ä¸€è¡Œå°±æ˜¯ä¸€ä¸ªå•ç‹¬çš„è¯å‘é‡ï¼Œå› æ­¤è®¡ç®—è¯ä¹‹é—´çš„ç›¸å…³æ€§å°±è½¬å˜æˆäº†è®¡ç®—è¯å‘é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œé‚£ä¹ˆå‘é‡ä¹‹é—´çš„ç›¸å…³æ€§æ€ä¹ˆè®¡ç®—å‘¢ï¼Ÿé‚£å°±æ˜¯å‘é‡çš„ç‚¹ç§¯ï¼Œç‚¹ç§¯å¯ä»¥è¡¨å¾ä¸¤ä¸ªå‘é‡çš„å¤¹è§’ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸€ä¸ªå‘é‡åœ¨å¦ä¸€ä¸ªå‘é‡ä¸Šçš„æŠ•å½±å€¼ï¼Œæ ¹æ®çº¿ä»£çš„çŸ¥è¯†ï¼Œä¸¤ä¸ªå‘é‡å‚ç›´å³çº¿æ€§æ— å…³ï¼Œæ­¤æ—¶å‘é‡çš„ç‚¹ç§¯ä¸º0ï¼Œå› æ­¤ä½¿ç”¨ç‚¹ç§¯å€¼æ¥è¡¨ç¤ºç›¸å…³æ€§æ˜¯å¾ˆè‡ªç„¶çš„äº‹ã€‚**\n",
    "\n",
    "![pic5](png/pic5.png)\n",
    "\n",
    "**æ¥ä¸‹æ¥å°±æ˜¯self-attentionçš„å…·ä½“è®¡ç®—è¿‡ç¨‹ï¼Œå…¶æ€»ä½“ç»“æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬éœ€è¦ä¼ å…¥ä¸‰ä¸ªçŸ©é˜µqueryï¼Œkeyå’Œvalueï¼ŒQå’ŒKç”¨æ¥è®¡ç®—æ³¨æ„åŠ›ç³»æ•°ï¼Œè®¡ç®—å¾—åˆ°çš„ç³»æ•°ç»è¿‡ç¼©æ”¾åè¾“å…¥softmaxå‡½æ•°å¾—åˆ°0-1ä¹‹é—´çš„ç³»æ•°å€¼ï¼Œå†å’ŒVç›¸ä¹˜ç»™æ¯ä¸€ä¸ªè¯å‘é‡åˆ†é…ç›¸åº”çš„æƒé‡ã€‚Q,K,Vå‡é€šè¿‡çº¿æ€§å˜æ¢å¾—åˆ°ä¸”çº¿æ€§å˜æ¢çš„ç³»æ•°æ˜¯å¯å­¦ä¹ çš„ï¼Œå³è®©ç½‘ç»œè‡ªå·±æ‰¾å‡ºæœ€é€‚åˆçš„å˜æ¢çŸ©é˜µã€‚**\n",
    "\n",
    "![pic6](png/pic6.png)\n",
    "\n",
    "**å¾—åˆ°Q,K,Våå°±è¦å¼€å§‹è®¡ç®—æ¯ä¸€ä¸ªè¯å‘é‡å’Œå…¶ä»–è¯å‘é‡çš„ç›¸å…³æ€§äº†ï¼Œå‰é¢è¯´è¿‡çŸ©é˜µçš„æ¯ä¸€è¡Œéƒ½ä»£è¡¨ä¸€ä¸ªè¯å‘é‡ï¼Œä½†å¦‚æœä¸¤ä¸ªå‘é‡è¦åšç‚¹ç§¯çš„è¯å°±å¿…é¡»ä¿è¯ä¸€ä¸ªæ˜¯è¡Œå‘é‡ä¸€ä¸ªæ˜¯åˆ—å‘é‡ï¼Œå› æ­¤åªè¦å°†KçŸ©é˜µåšä¸€ä¸ªè½¬ç½®ï¼Œè¡Œå‘é‡å°±å˜æˆäº†åˆ—å‘é‡ï¼Œç„¶åæ ¹æ®çŸ©é˜µçš„è¿ç®—è§„åˆ™ï¼ŒQçš„ç¬¬ä¸€è¡Œå’ŒKçš„æ¯ä¸€åˆ—åšç‚¹ç§¯è¿ç®—å¾—åˆ°è¾“å‡ºçŸ©é˜µçš„ç¬¬ä¸€è¡Œï¼Œè¿™æ ·å°±å¾—åˆ°äº†ç¬¬ä¸€ä¸ªè¯å’Œå…¶ä»–æ¯ä¸ªè¯ä¹ŸåŒ…æ‹¬å®ƒè‡ªå·±æœ¬èº«çš„ç›¸å…³å€¼äº†ï¼Œå…¶å®ƒè¡ŒåŒç†ã€‚åœ¨è§‚å¯Ÿè¿™ä¸¤ä¸ªçŸ©é˜µçš„è¿ç®—è¿‡ç¨‹æˆ‘ä»¬ä¼šæƒŠå–œçš„å‘ç°çŸ©é˜µçš„è¡Œå’Œåˆ—çš„è®¡ç®—æ˜¯åŒæ—¶è¿›è¡Œçš„ï¼Œæˆ‘ä»¬é€šè¿‡ä¸€æ¬¡çŸ©é˜µè¿ç®—å°±å¾—åˆ°äº†æ¯ä¸€ä¸ªè¯å’Œå…¶ä»–è¯çš„ç›¸å…³å€¼ï¼Œè¿™å°±æ˜¯çŸ©é˜µå¹¶è¡Œè®¡ç®—çš„é­…åŠ›ã€‚$QK^{T}$å¾—åˆ°ç›¸å…³å€¼åä¸ºä»€ä¹ˆåˆé™¤äº†$\\sqrt{d_{k}}$ï¼Ÿé‚£æ˜¯å› ä¸ºæ¯ä¸ªè¯åœ¨ç»è¿‡embeddingç¼–ç åéƒ½å˜æˆäº†å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„ç‹¬ç«‹éšæœºåˆ†å¸ƒè¯å‘é‡ï¼ŒQå’ŒKæ¯ä¸ªè¯å‘é‡çš„ç»´åº¦éƒ½ä¸º$d_{k}$ï¼Œ$QK^{T}$åå°±å¾—åˆ°ä¸€ä¸ª$d_{k}xd_{k}$çš„æ–¹é˜µï¼Œå› ä¸ºè¯å‘é‡ä¹‹é—´éƒ½æ˜¯ç‹¬ç«‹åˆ†å¸ƒçš„ï¼Œå› æ­¤ç‚¹ç§¯åå¾—åˆ°çš„å‘é‡çš„å‡å€¼å’Œæ–¹å·®ç­‰äºæ‰€æœ‰è¯å‘é‡çš„å‡å€¼å’Œæ–¹å·®ä¹‹å’Œï¼Œæ‰€ä»¥ç‚¹ç§¯åçš„å‘é‡çš„å‡å€¼å’Œæ–¹å·®ä¸º0å’Œ$d_{k}$ï¼Œç”±äº$d_{k}$é€šå¸¸éƒ½ä¼šå¾ˆå¤§ï¼Œè¿™ä¼šå¯¼è‡´å‘é‡é‡Œçš„å€¼å‘ˆç°ä¸€ä¸ªéå¸¸å¤§çš„æ•°é‡çº§ï¼Œå¦‚æœç›´æ¥ä¼ å…¥softmaxå‡½æ•°å°±ä¼šè¿›å…¥é¥±å’ŒåŒºï¼Œè€Œé¥±å’ŒåŒºçš„æ¢¯åº¦å‡ ä¹ä¸º0ï¼Œè¿™æ ·åœ¨åå‘ä¼ æ’­æ—¶å°±ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±é—®é¢˜è€Œæ— æ³•è®­ç»ƒï¼Œæ‰€ä»¥é™¤ä»¥$\\sqrt{d_{k}}$ä½¿å¾—æ¯ä¸ªè¯å‘é‡åˆå›åˆ°å‡å€¼0ï¼Œæ–¹å·®1çš„åˆ†å¸ƒã€‚**\n",
    "\n",
    "![pic7](png/pic7.png)\n",
    "\n",
    "**å¾—åˆ°ç›¸å…³å€¼åè¾“å…¥softmaxå‡½æ•°ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯è¿™é‡Œçš„softmaxå‡½æ•°æ˜¯å¯¹çŸ©é˜µçš„æ¯ä¸€è¡Œåšï¼Œä½¿å¾—æ¯ä¸€è¡Œçš„å’Œä¸º1ã€‚**\n",
    "\n",
    "![pic8](png/pic8.png)\n",
    "\n",
    "**ä»softmaxå‡½æ•°å‡ºæ¥çš„çŸ©é˜µå³ä¸ºæˆ‘ä»¬éœ€è¦çš„attentionç³»æ•°çŸ©é˜µï¼ŒçŸ©é˜µçš„æ¯ä¸€è¡Œå³ä¸ºå½“å‰è¯å’Œå…¶ä»–è¯åŒ…æ‹¬è‡ªèº«çš„attentionç³»æ•°ï¼Œæ¯”å¦‚çŸ©é˜µçš„ç¬¬ä¸€è¡Œå³ä¸ºå•è¯1åˆ†åˆ«å’Œå•è¯1ï¼Œ2ï¼Œ3ï¼Œ4çš„attentionç³»æ•°ï¼Œå› æ­¤æ ¹æ®çŸ©é˜µä¹˜æ³•çš„è¿ç®—è§„åˆ™ï¼Œå•è¯1çš„è¾“å‡º$Z_{1}$å°±ä¸ºæ¯ä¸ªè¯çš„attentionç³»æ•°å’Œå¯¹åº”è¯å‘é‡çš„çº¿æ€§åŠ æƒã€‚**\n",
    "\n",
    "![pic9](png/pic9.png)\n",
    "\n",
    "![pic10](png/pic10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2ee9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_Dot_Product_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        # è¾“å…¥ä¸ºä¸€ä¸ªå››ç»´çš„çŸ©é˜µï¼Œ[batch,heads,seq_len,d_k or d_v]\n",
    "        # ç›´æ¥ä½¿ç”¨å››ç»´çŸ©é˜µï¼Œå……åˆ†åˆ©ç”¨çŸ©é˜µå¹¶è¡Œè¿ç®—\n",
    "        batch,heads,seq_len,d = v.size()\n",
    "        k_t = k.transpose(2,3)\n",
    "        atten_score = (q @ k_t) / torch.sqrt(torch.tensor(d))\n",
    "        \n",
    "        if mask is not None:\n",
    "            assert mask.shape == atten_score.shape,'mask shape {} is not equal to attention score shape {}.'.format(mask.shape,atten_score.shape)\n",
    "            atten_score = atten_score.masked_fill(mask==0,-1e6) #ç”¨æå°å€¼å¡«å……ä½¿å¾—softmaxåå€¼ä¸º0\n",
    "        \n",
    "        score = self.softmax(atten_score)\n",
    "        value = score @ v\n",
    "        # TODO:è¿”å›scoreä¾¿äºåç»­å®ç°å¯è§†åŒ–attentionç³»æ•°çš„heatmap\n",
    "        return score,v\n",
    "        \n",
    "\n",
    "\n",
    "class Mutil_Head_Attention(nn.Module):\n",
    "    def __init__(self,d_model,d_k,d_v,heads,mask=None,is_visual=False):\n",
    "        super().__init__()\n",
    "        self.q_w = nn.Linear(d_model,d_model)\n",
    "        self.k_w = nn.Linear(d_model,d_model)\n",
    "        self.v_w = nn.Linear(d_model,d_model)\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.mask = mask\n",
    "        self.is_visual = is_visual\n",
    "        self.attention = Scaled_Dot_Product_Attention()\n",
    "        self.lin_concat = nn.Linear(d_model,d_model)\n",
    "        \n",
    "        \n",
    "    def split_tensor(self,x):\n",
    "        batch,seq_len,d_model = x.size()\n",
    "        assert d_model // self.heads == self.d_k == self.d_v,'d_k mutilply heads not equal to d_model.'\n",
    "        mutil_head_tensor = x.view(batch,seq_len,self.heads,d_model//self.heads).transpose(1,2)\n",
    "        return mutil_head_tensor\n",
    "    \n",
    "\n",
    "        \n",
    "    def forward(self,q,k,v):\n",
    "        # shape[batch,seq_len,d_model]\n",
    "        q,k,v = self.q_w(q),self.k_w(k),self.v_w(v)\n",
    "        \n",
    "        # æŒ‰headsæ•°æ‹†åˆ†æˆå››ç»´çŸ©é˜µ\n",
    "        mutil_head_q,mutil_head_k,mutil_head_v = self.split_tensor(q),self.split_tensor(k),self.split_tensor(v)\n",
    "        score,value = self.attention(mutil_head_q,mutil_head_k,mutil_head_v,mask=self.mask)\n",
    "    \n",
    "        # concatå›åŸæ¥çš„ç»´åº¦ï¼Œå› ä¸ºæ˜¯å››ç»´çŸ©é˜µæ‰€ä»¥ç›´æ¥reshapeå°±èƒ½æå®š\n",
    "        batch,heads,seq_len,d = value.size()\n",
    "        out = value.transpose(1,2).contiguous().view(batch,seq_len,heads * d)\n",
    "        out = self.lin_concat(out)\n",
    "        if self.is_visual:\n",
    "            return score,out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b744cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# æ¨¡å—æµ‹è¯•,è¾“å…¥å’Œè¾“å‡ºç»´åº¦ä¸€è‡´åˆ™é€šè¿‡\n",
    "attention = Mutil_Head_Attention(4,2,2,2)\n",
    "out = attention(emb_out,emb_out,emb_out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5df17",
   "metadata": {},
   "source": [
    "# layer normalization\n",
    "\n",
    "![pic11.png](png/pic11.png)\n",
    "\n",
    "**ä¸Šå›¾æ˜¯æ¥è‡ªä½•å‡¯æ˜è®ºæ–‡ä¸­å¯¹äºå››ç§ä¸åŒå½’ä¸€åŒ–æ–¹æ³•çš„å½¢è±¡è¡¨ç¤ºï¼Œé€šè¿‡è¿™å¼ å›¾æˆ‘ä»¬èƒ½å¾ˆæ¸…æ¥šçš„çœ‹å‡ºbatch normå’Œlayer normä¹‹é—´çš„åŒºåˆ«ï¼Œbatch normæ˜¯å¯¹ä¸€ä¸ªbatchå†…æ‰€æœ‰è¾“å…¥ç›¸åŒé€šé“çš„æ•°æ®åšå½’ä¸€åŒ–ï¼Œæ˜¯ä¸€ç§çºµå‘çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œè€Œlayer normæ˜¯å¯¹batchå†…æ¯ä¸ªè¾“å…¥æ•°æ®å•ç‹¬åšå½’ä¸€åŒ–ï¼Œæ˜¯ä¸€ç§æ¨ªå‘çš„å½’ä¸€åŒ–æ–¹æ³•ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆtransformerä½¿ç”¨çš„æ˜¯layer normå‘¢ï¼Ÿå› ä¸ºé’ˆå¯¹å¤šä¸ªè¯­å¥è¾“å…¥ï¼Œæˆ‘ä»¬æ›´å…³æ³¨çš„æ˜¯æ¯ä¸ªè¯­å¥å†…ä¸åŒè¯ä¹‹é—´çš„åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å¤šä¸ªè¯­å¥çš„è®¸å¤šè¯ä¹‹é—´çš„åˆ†å¸ƒï¼Œå› æ­¤ä½¿ç”¨layer normæ¥è¿›è¡Œå½’ä¸€åŒ–ã€‚layer normçš„å…¬å¼å’Œbatch normä¸€æ ·éƒ½æ˜¯å‡å»å‡å€¼é™¤ä»¥æ ‡å‡†å·®è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†è¦æ³¨æ„çš„æ˜¯åœ¨æ ‡å‡†åŒ–ä¹‹åè¿˜åŠ ä¸Šäº†å‚æ•°å¯å­¦ä¹ çš„çº¿æ€§ç¼©æ”¾ï¼Œå› ä¸ºæ ‡å‡†çš„å½’ä¸€åŒ–å¯èƒ½ä¼šå°†ä¸‹å±‚ç¥ç»å…ƒçš„ç»“æœç²—æš´çš„è°ƒæ•´åˆ°å½’ä¸€åŒ–åŒºé—´ï¼Œè¿™ä¼šé™ä½ç¥ç»ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe5cceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Norm(nn.Module):\n",
    "    def __init__(self,d_model,eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        # ä¸ºäº†å’Œpytorchçš„å®˜æ–¹å®ç°ä¿æŒä¸€è‡´ï¼Œé‡‡ç”¨æ— åä¼°è®¡è®¡ç®—æ–¹å·®\n",
    "        var = x.var(dim=-1,unbiased=False,keepdim=True)\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.alpha * out + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "104109b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2760, 0.8115, 0.1931],\n",
      "         [0.7855, 0.7638, 0.2516],\n",
      "         [0.8911, 0.5841, 0.9164]]])\n",
      "tensor([[[-0.5505,  1.4033, -0.8528],\n",
      "         [ 0.7505,  0.6627, -1.4132],\n",
      "         [ 0.6217, -1.4106,  0.7889]]], grad_fn=<AddBackward0>)\n",
      "tensor([[[-0.5505,  1.4033, -0.8528],\n",
      "         [ 0.7505,  0.6627, -1.4132],\n",
      "         [ 0.6217, -1.4106,  0.7889]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ï¼Œå’Œpytorchå®˜æ–¹å®ç°ç»“æœå¯¹æ¯”\n",
    "a = torch.rand(1,3,3)\n",
    "layer_norm = Layer_Norm(3)\n",
    "out1 = layer_norm(a)\n",
    "out2 = nn.LayerNorm(3)(a)\n",
    "print(a)\n",
    "print(out1)\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a941f",
   "metadata": {},
   "source": [
    "ç»“æœå®Œå…¨ç›¸åŒï¼Œå…¶å®ä¹Ÿæ²¡é‚£ä¹ˆéš¾å˜›ï½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9849a63",
   "metadata": {},
   "source": [
    "## feed forward layer\n",
    "å°±æ˜¯ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œç¬¬ä¸€ä¸ªè¿æ¥å±‚æ‰©å……ç»´åº¦ï¼Œç¬¬äºŒä¸ªè¿æ¥å±‚å‹ç¼©å›åŸæ¥çš„ç»´åº¦ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ç›¸åŒï¼Œæ²¡ä»€ä¹ˆå¯è¯´çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25c840d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feed_Forward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,p_prob):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(d_model,d_ff)\n",
    "        self.layer2 = nn.Linear(d_ff,d_model)\n",
    "        self.drop = nn.Dropout(p=p_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8abc9f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# æ¨¡å—æµ‹è¯•\n",
    "arr_tensor = torch.rand(1,3,3)\n",
    "out = Feed_Forward(3,5,0.1)(arr_tensor)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a1155",
   "metadata": {},
   "source": [
    "# encoder\n",
    "**ä¸Šé¢å±•ç¤ºçš„æ˜¯ä¸€å±‚ç¼–ç å™¨å±‚ï¼Œencoderå°±æ˜¯å°†ç¼–ç å™¨é‡å¤å †å æ•°å±‚ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3084ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Layer(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,heads,d_k,d_v,p_prob):\n",
    "        super().__init__()\n",
    "        self.attention = Mutil_Head_Attention(d_model,d_k,d_v,heads)\n",
    "        self.norm1 = Layer_Norm(d_model)\n",
    "        self.drop1 = nn.Dropout(p=p_prob)\n",
    "        self.ffn = Feed_Forward(d_model,d_ff,p_prob)\n",
    "        self.norm2 = Layer_Norm(d_model)\n",
    "        self.drop2 = nn.Dropout(p=p_prob)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        identity_1 = x\n",
    "        out = self.attention(x,x,x)\n",
    "        out = self.norm1(torch.add(identity_1,self.drop1(out)))\n",
    "        identity_2 = out\n",
    "        out = self.ffn(out)\n",
    "        output = self.norm2(torch.add(identity_2,self.drop2(out)))\n",
    "        return output\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,heads,d_k,d_v,p_prob,n_layers):\n",
    "        super().__init__()\n",
    "        self.encoder = self.make_layers(d_model,d_ff,heads,d_k,d_v,p_prob,Encoder_Layer,n_layers)\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_layers(d_model,d_ff,heads,d_k,d_v,p_prob,layer,n_layers):\n",
    "        layers = [layer(d_model,d_ff,heads,d_k,d_v,p_prob) for _ in range(n_layers)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.encoder(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3369f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•\n",
    "a = torch.rand(1,3,4)\n",
    "out = Encoder(4,8,2,2,2,0.1,6)(a)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5518e0d3",
   "metadata": {},
   "source": [
    "# decoder\n",
    "**decoderåŒç†ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "040e2ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_layer(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,heads,d_k,d_v,p_prob,mask):\n",
    "        super().__init__()\n",
    "        self.mask_attention = Mutil_Head_Attention(d_model,d_k,d_v,heads,mask=mask)\n",
    "        self.norm1 = Layer_Norm(d_model)\n",
    "        self.drop1 = nn.Dropout(p=p_prob)\n",
    "        self.attention = Mutil_Head_Attention(d_model,d_k,d_v,heads)\n",
    "        self.norm2 = Layer_Norm(d_model)\n",
    "        self.drop2 = nn.Dropout(p=p_prob)\n",
    "        self.ffn = Feed_Forward(d_model,d_ff,p_prob)\n",
    "        self.norm3 = Layer_Norm(d_model)\n",
    "        self.drop3 = nn.Dropout(p=p_prob)\n",
    "        \n",
    "    def forward(self,x_encoder,x_decoder):\n",
    "        identity_dec = x_decoder\n",
    "        out = self.mask_attention(x_decoder,x_decoder,x_decoder)\n",
    "        out = self.norm1(torch.add(identity_dec,self.drop1(out)))\n",
    "        identity_1 = out\n",
    "        out = self.attention(out,x_encoder,x_encoder)\n",
    "        out = self.norm2(torch.add(identity_1,self.drop2(out)))\n",
    "        identity_2 = out\n",
    "        out = self.ffn(out)\n",
    "        output = self.norm3(torch.add(identity_2,self.drop3(out)))\n",
    "        return output\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,heads,d_k,d_v,p_prob,mask,n_layers):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.ModuleList([Decoder_layer(d_model,d_ff,heads,d_k,d_v,p_prob,mask) for _ in range(n_layers)])\n",
    "        \n",
    "    def forward(self,x_enc,x_dec):\n",
    "        for layer in self.decoder:\n",
    "            x_dec = layer(x_enc,x_dec)\n",
    "        \n",
    "        return x_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "33ddf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•\n",
    "mask = torch.tril(torch.ones(1,2,3,3))\n",
    "inp1 = torch.rand(1,3,6)\n",
    "inp2 = torch.rand(1,3,6)\n",
    "out = Decoder(6,8,2,3,3,0.1,mask,6)(inp1,inp2)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa0547",
   "metadata": {},
   "source": [
    "## transformer\n",
    "**ç»ˆäºå®šä¹‰å®Œäº†æ‰€æœ‰çš„éœ€è¦ç”¨åˆ°çš„æ¨¡å—ï¼Œç°åœ¨åªéœ€è¦å°†å®ƒä»¬æŒ‰ç…§ä¸€å®šè§„åˆ™ç»„åˆèµ·æ¥å°±å®Œæˆå•¦ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘æœ€å–œæ¬¢pytorchæ¡†æ¶çš„ä¸€ç‚¹ï¼Œå°±åƒå°æ—¶å€™ç©çš„ä¹é«˜ç§¯æœ¨ä¸€æ ·ï¼Œåªè¦å°†æ‰€æœ‰çš„ç§¯æœ¨æ‰¾é½ä¸€å±‚å±‚æ­èµ·æ¥å°±èƒ½å¾—åˆ°ä½ æƒ³è¦çš„ç»“æ„ã€‚**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba055908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,voc_num,d_model,d_ff,heads,d_k,d_v,p_prob,mask,enc_layers,dec_layers):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(voc_num,d_model,p_prob)\n",
    "        self.Encoder = Encoder(d_model,d_ff,heads,d_k,d_v,p_prob,enc_layers)\n",
    "        self.Decoder = Decoder(d_model,d_ff,heads,d_k,d_v,p_prob,mask,dec_layers)\n",
    "        self.linear = nn.Linear(d_model,voc_num)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "     \n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        x_enc = self.emb(x)\n",
    "        x_dec = self.emb(y)\n",
    "        out = self.Encoder(x_enc)\n",
    "        identity_enc = out\n",
    "        out = self.Decoder(identity_enc,x_dec)\n",
    "        out = self.linear(out)\n",
    "        output = self.softmax(out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cd3dfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 10])\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•\n",
    "x = torch.LongTensor([[1,3,4,5,2,2],[2,3,5,6,7,9],[4,3,7,5,2,8]])\n",
    "y = torch.LongTensor([[1,3,4,5,2,2],[2,3,5,6,7,9],[4,3,7,5,2,8]])\n",
    "voc_num = 10\n",
    "d_model = 6\n",
    "d_ff = 10\n",
    "heads = 2\n",
    "d_k = 3\n",
    "d_v = 3\n",
    "p_prob = 0.1\n",
    "mask = torch.tril(torch.ones(3,2,6,6))\n",
    "enc_layers = 6\n",
    "dec_layers = 6\n",
    "transformer = Transformer(voc_num,d_model,d_ff,heads,d_k,d_v,p_prob,mask,enc_layers,dec_layers) \n",
    "output = transformer(x,y)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb17f0d",
   "metadata": {},
   "source": [
    "__æ•´ä¸ªæ¨¡å‹æ­å»ºå®Œæ¯•ï¼Œå¸Œæœ›èƒ½é€šè¿‡æ•´ä¸ªæµç¨‹ä½¿çš„çœ‹æ–‡æ¡£çš„äººå¯¹transformeræ¶æ„æœ‰ä¸€ä¸ªæ›´æ·±åˆ»çš„è®¤è¯†ï¼Œkeep learning is all we needğŸ˜€__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889c3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
